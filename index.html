<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CZ-Net</title>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
rel="stylesheet">

<link rel="stylesheet" href="./static/css/bulma.min.css">
<link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
<link rel="stylesheet" href="./static/css/bulma-slider.min.css">
<link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
<link rel="stylesheet"
href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<link rel="stylesheet" href="./static/css/index.css">
</head>


<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>CZ-Net</title>
	<!-- <link rel="stylesheet" href="http://cdn.static.runoob.com/libs/bootstrap/3.3.7/css/bootstrap.min.css"> -->
	<link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
	<!-- <link rel="stylesheet" type="text/css" href="css/mystyle.css"> -->
	<script src="http://cdn.static.runoob.com/libs/jquery/2.1.1/jquery.min.js"></script>
	<link rel="stylesheet" href="bootstrap/js/bootstrap.min.js">
</head>

<body>
	<div class="container">
		<div class="content">
			<h1 style="text-align:center; margin-top:60px; font-weight: bold">
				<!-- Motion Deblurring with Low-Resolution Events -->
				CrossZoom: A Unified Architecture for Motion Deblurring and Event Super-Resolving 
			</h1>
			<p style="text-align:center; margin-bottom:15px; margin-top:20px; font-size: 18px">
				<a>Chi Zhang<sup>1</sup></a>,
				<a href="https://xiangz-0.github.io/" target="_blank">Xiang Zhang<sup>2</sup></a>,
				<a href="https://dvs-whu.cn/" target="_blank">Lei Yu<sup>1,*</sup></a>
				<!-- <a href="http://people.ucas.ac.cn/~shyli" target="_blank">Shengyang Li<sup>3</sup></a>, -->
				<!-- <a href="http://www.captain-whu.com/yangwen.html" target="_blank">Wen Yang<sup>2,3</sup></a>,  -->
				<!-- <a href="https://sites.google.com/site/michaelyingyang/home" target="_blank">Michael Ying Yang<sup>5</sup></a>, -->
				<!-- <a href="https://www.sipeo.bgu.tum.de/team/zhu" target="_blank">Xiao Xiang Zhu<sup>6</sup></a>, -->
				<!-- <a target="_blank">Wen Yang<sup>1</sup></a>,
        		<a target="_blank">Chu He<sup>1</sup></a>,
        <a target="_blank">Cheng Li<sup>2</sup></a>,
        <a target="_blank">Jian-Zhuang Liu<sup>2</sup></a>,            
				<a href="http://www.captain-whu.com/xia_En.html" target="_blank">Gui-Song Xia<sup>2</sup></a> -->
			</p>
			<p style="text-align:center; margin-bottom:15px; margin-top:20px; font-size: 15px;font-style: italic;">
				1. School of Electronic Information, Wuhan University, Wuhan 430079, China <br>
				2. Computer Vision Lab of ETH Zurich, Switzerland <br>
				<!-- 3. School of Computer Science, Wuhan University, Wuhan 430079, China <br> -->
				<!-- 3. Key Laboratory of Space Utilization, Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, Beijing 100094, China <br> -->
				<!-- 4. School of Electronic Information, Wuhan University, Wuhan 430072, China <br> -->
				<!-- 5. Faculty of Geo-Information Science and Earth Observation, University of Twente, Hengelosestraat 99, Enschede, Netherlands <br> -->
				<!-- 6. German Aerospace Center (DLR) and also Technical University of Munich, Germany -->
			</p>

		</div>

		<!-- <br><hr> -->

		<div class="row">
			<div class="span6 offset2">
				<ul class="nav nav-tabs">
					<br />
				</ul>
			</div>
		</div>

		<!-- <table style= "width:100%;" align="center">-->
<!--			<tr>-->
<!--				<td style="text-align: center;"><a href="#RoadMap" ><img src="files/RoadMap-Head.jpg" class="img-responsive center-block"/> <br> Road map</a></td>-->
<!--				&nbsp;&nbsp;&nbsp;&nbsp;-->
<!--				<td style="text-align: center;"><a href="https://captain-whu.github.io/DiRS/" target="_blank"><img src="files/Million-AID-Head.jpg" class="img-responsive center-block" /> <br> Million-AID</a></td>-->
<!--				&nbsp;&nbsp;&nbsp;&nbsp;-->
<!--				<td style="text-align: center;"><a href="https://arxiv.org/pdf/2201.01953.pdf" target="_blank"><img src="files/Paper-Header.png" class="img-responsive center-block" /> <br> Paper</a></td>-->
<!--				&nbsp;&nbsp;&nbsp;&nbsp;-->
<!--				<td style="text-align: center;"><a href="files/ASP-PPT.pdf" target="_blank" ><img src="files/PPT-Head.png" class="img-responsive center-block" /> <br> PPT</a></td>-->
<!--			</tr>-->
<!--		 </table> -->

		<br>
		<div class="row">
			<div class="span12">
				<img src="files/esr_md_png.png" width="80%" class="img-responsive center-block" />
			</div>
		</div>


		<div class="row"> 
			<div class="span12">
				<h2 style="text-align:left; margin-bottom:-10px; margin-top:20px; ">
					Introduction 
				</h2>
				
				<div class="row">
					<div class="span6 offset2">
						<ul class="nav nav-tabs">
							<br />
						</ul>
					</div>
				</div>
				<br>
				<p style="text-align:justify; font-size: 17px">
					Even though collaborating with neuromorphic event cameras brings prosperity to traditional frame-based vision applications, the performance is still confined by 
					the resolution gap crossing two modalities in both spatial and temporal domains. This paper is devoted to bridging the gap by increasing the temporal resolution for images, 
					i.e., motion deblurring, and the spatial resolution for events, i.e., event super-resolving, respectively. To this end, we propose CrossZoom, a novel unified 
					neural Network (CZ-Net) to jointly recover sharp latent images at arbitrary timestamps within the exposure period of blurry input and the corresponding high-resolution 
					events. Specifically, the implicit time-encoding and multiscale blur-event fusion architectures are presented to achieve arbitrary timestamp recovery and scale-variant enhancement. 
					Attention-based adaptive enhancement and cross-interaction prediction modules are designed to alleviate the distortions embedded in LR events and reinforce the final results 
					through the prior blur-event complementary information. Furthermore, we propose a new dataset containing high-resolution, sharp image sequences and the corresponding real LR event 
					streams to bridge the gap between the synthetic and real-world datasets. Extensive qualitative and quantitative experiments on synthetic and real-world datasets demonstrate the 
					effectiveness and robustness of the proposed method.
				</p>
				<img src="files/fr.png" width="950px" class="img-responsive center-block" />
			</div>
		</div>

		<br>
		<div class="row">
			<div class="span12">
				<h2 id="scbm" style="text-align:left; margin-bottom:-10px; margin-top:20px;">
					Cross-Resolution Deblurring Dataset
				</h2>
				<div class="row">
					<div class="span6 offset2">
						<ul class="nav nav-tabs">
							<br />
						</ul>
					</div>
				</div>
				<br>
				<p style="text-align:justify; font-size: 17px">
					To the best of our knowledge, no publicly released dataset is available yet for Motion Deblurring and Event Super-Reosolving with Low-Resolution (LR) events. It motivates us to build
					 a new dataset for Cross-Resolution Deblurring and Resolving (CRDR) containing High Resolution (HR) sharp and blurry images and the corresponding <i>real-world</i> LR event streams. 
					 To simultaneously collect images and events, we build a hybrid camera system composed of an LR DAVIS346 event camera of resolution 346*260 and an HR FLIR BlackFly U332S4 RGB 
					 camera of resolution 2048*1536 working at a frame rate of 118 FPS. A beam splitter connects two cameras to achieve minimum spatial parallax 
					 between RGB frames and events. Since two cameras provide vision perceptions of different modalities and spatial resolutions, calibrations in both spatial and temporal domains are 
					 essential to ensure alignments between collected RGB frames and events.
				</p>
				<img src="files/crdr_dataset_png.png" width="1150px" class="img-responsive center-block" />
			</div>
		</div>


		<br>
		
		<section class="hero  is-small">
			<div class="hero-body">
			  <!-- </div> -->
			  <div class="span12">
				<h2 id="Million-AID" style="text-align:left; margin-bottom:-20px; margin-top:00px;">
					More Results of Motion Deblurring
				</h2>
				<div class="row">
					<div class="span6 offset2">
						<ul class="nav nav-tabs">
							<br />
						</ul>
					</div>
				</div>
				<br>
			</div>
			  <div class="container " style="width: 100%;"> 
				<div id="results-carousel1" class="carousel results-carousel">

					<div class="item item-toby">
					
					<video poster="" id="Couryard" autoplay controls muted loop playsinline height="100%">
						<source src="./files/video/video_show_GoPro_1.mp4"
								type="video/mp4">
					</video>
					</div>
	
					<div class="item item-toby">
					
					<video poster="" id="Couryard" autoplay controls muted loop playsinline height="100%">
						<source src="./files/video/video_show_GoPro_2.mp4"
								type="video/mp4">
					</video>
					</div>

				  <div class="item item-toby">
					
					<video poster="" id="Stone" autoplay controls muted loop playsinline height="100%">
					  <source src="./files/video/video_show_CRDR_3.mp4"
							  type="video/mp4">
					</video>
				  </div>
				  <div class="item item-toby">
					
					<video poster="" id="Stone" autoplay controls muted loop playsinline height="100%">
					  <source src="./files/video/video_show_CRDR_2.mp4"
							  type="video/mp4">
					</video>
				  </div>

				  <div class="item item-toby">
					
					<video poster="" id="Couryard" autoplay controls muted loop playsinline height="100%">
					  <source src="./files/video/video_show_CRDR_1.mp4"
							  type="video/mp4">
					</video>
				  </div>

			  	</div>
			</div>
		  </section>

		  <br>


		  <section class="hero  is-small">
			<div class="hero-body">
			  <!-- </div> -->
			  <div class="span12">
				<h2 id="Million-AID" style="text-align:left; margin-bottom:-20px; margin-top:00px;">
					More Results of Event Super-Resolving
				</h2>
				<div class="row">
					<div class="span6 offset2">
						<ul class="nav nav-tabs">
							<br />
						</ul>
					</div>
				</div>
				<br>
			</div>
			  <div class="container " style="width: 100%;"> 
				<div id="results-carousel1" class="carousel results-carousel">

					<div class="item item-toby">
					
					<video poster="" id="Couryard" autoplay controls muted loop playsinline height="100%">
						<source src="./files/video/video_show_GoPro1_ESR.mp4"
								type="video/mp4">
					</video>
					</div>

					<div class="item item-toby">
					
						<video poster="" id="Couryard" autoplay controls muted loop playsinline height="100%">
							<source src="./files/video/video_show_GoPro1_2_ESR.mp4"
									type="video/mp4">
						</video>
						</div>

					<div class="item item-toby">
				
						<video poster="" id="Couryard" autoplay controls muted loop playsinline height="100%">
							<source src="./files/video/video_show_GoPro2_ESR.mp4"
									type="video/mp4">
						</video>
						</div>
	
					<div class="item item-toby">
					
					<video poster="" id="Couryard" autoplay controls muted loop playsinline height="100%">
						<source src="./files/video/video_show_GoPro2_2_ESR.mp4"
								type="video/mp4">
					</video>
					</div>

			  	</div>
			</div>
		  </section>


		<br>
		<div class="row">
			<div class="span12">

				<div class="section bibtex">

					<h3 style="text-align:left; margin-bottom:10px; margin-top:20px; font-weight: bold">
						Citation
					</h3>
					<pre>
@misc{Zhang2023CrossZoom,
title={CrossZoom: A Unified Architecture for Motion Deblurring and Event Super-Resolving},
author={Zhang, Chi and Zhang, Xiang and Yu, Lei},
year={2023},
journal={arXiv},
primaryClass={cs.CV}
}
</pre>
	                <br>

				</div>
				<h3 style="text-align:left; margin-bottom:10px; margin-top:20px; font-weight: bold">
					Contact
				</h3>
				<p>
					If you have any problem, please contact:
				<ul>
					<li>Chi Zhang at <strong>zhangchi1@whu.edu.cn</strong></li>
					<li>Lei Yu at <strong>ly.wd@whu.edu.cn</strong></li>
				</ul>
				<br />
				<br />
				<br />
			</div>
		</div>

<!-- 		<div class="row">
			<div style="text-align:center; margin-top:0; margin-bottom: 20px;">
				<embed id="map" src="http://rf.revolvermaps.com/f/f.swf" type="application/x-shockwave-flash" pluginspage="http://www.macromedia.com/go/getflashplayer" wmode="transparent" allowScriptAccess="always" allowNetworking="all" width="150" height="75" flashvars="m=0&amp;i=5dp1mfnunae&amp;r=10&amp;c=fffdc0" loop="true" autostart="False"></embed> 
				<img class="img-responsive center-block" src="http://rf.revolvermaps.com/js/c/5dp1mfnunae.gif" width="1" height="1" alt="" value="True"/>
				<a style="font-size: x-small;"> Copyight@2020, Captain</a>
				<a href="http://www.revolvermaps.com/livestats/5dp1mfnunae/"></a>
			</div>
		</div> -->
</body>
<script defer src="./static/js/fontawesome.all.min.js"></script>
<script src="./static/js/bulma-carousel.min.js"></script>
<script src="./static/js/bulma-slider.min.js"></script>
<script src="./static/js/index.js"></script>
<script src="./static/js/video_comparison.js"></script>
</html>
